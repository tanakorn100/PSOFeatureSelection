{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Subset Selection\n",
    "In this example, we'll be using the optimizer `pyswarms.discrete.BinaryPSO` to perform feature subset selection to improve classifier performance. But before we jump right on to the coding, let's first explain some relevant concepts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A short primer on feature selection\n",
    "\n",
    "The idea for feature subset selection is to be able to find the best features that are suitable to the classification task. We must understand that not all features are created equal, and some may be more relevant than others. Thus, if we're given an array of features, how can we know the most optimal subset? (yup, this is a rhetorical question!)\n",
    "\n",
    "For a Binary PSO, the position of the particles are expressed in two terms: `1` or `0` (or on and off). If we have a particle $x$ on $d$-dimensions, then its position can be defined as:\n",
    "\n",
    "$$x = [x_1, x_2, x_3, \\dots, x_d] ~~~\\text{where}~~~ x_i \\in {0,1}$$\n",
    "\n",
    "In this case, the position of the particle for each dimension can be seen as a simple matter of on and off. \n",
    "\n",
    "### Feature selection and the objective function\n",
    "\n",
    "Now, suppose that we're given a dataset with $d$ features. What we'll do is that we're going to _assign each feature as a dimension of a particle_. Hence, once we've implemented Binary PSO and obtained the best position, we can then interpret the\n",
    "binary array (as seen in the equation above) simply as turning a feature on and off. \n",
    "\n",
    "As an example, suppose we have a dataset with 5 features, and the final best position of the PSO is:\n",
    "\n",
    "```python\n",
    ">>> optimizer.best_pos\n",
    "np.array([0, 1, 1, 1, 0])\n",
    ">>> optimizer.best_cost\n",
    "0.00\n",
    "```\n",
    "\n",
    "Then this means that the second, third, and fourth (or first, second, and third in zero-index) that are turned on are the selected features for the dataset. We can then train our classifier using only these features while dropping the others. How do we then define our objective function? (Yes, another rhetorical question!). We can design our own, but for now I'll be taking an equation from the works of [Vieira, Mendoca, Sousa, et al. (2013)](http://www.sciencedirect.com/science/article/pii/S1568494613001361).\n",
    "\n",
    "$$f(X) = \\alpha(1-P) + (1-\\alpha) \\left(1 - \\dfrac{N_f}{N_t}\\right)$$\n",
    "\n",
    "Where $\\alpha$ is a hyperparameter that decides the tradeoff between the classifier performance $P$, and the size of the feature subset $N_f$ with respect to the total number of features $N_t$. The classifier performance can be the accuracy, F-score, precision, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "#code below used to deal with special characters on the file path during read_csv()\n",
    "sys._enablelegacywindowsfsencoding() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install pyswarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt #MatPlotLib usado para desenhar o gráfico criado com o NetworkX\n",
    "\n",
    "# Import PySwarms\n",
    "import pyswarms as ps\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a toy dataset using scikit-learn\n",
    "We'll be using `sklearn.datasets.make_classification` to generate a 100-sample, 15-dimensional dataset with three classes. We will then plot the distribution of the features in order to give us a qualitative assessment of the feature-space.\n",
    "\n",
    "For our toy dataset, we will be rigging some parameters a bit. Out of the 10 features, we'll have only 5 that are informative, 5 that are redundant, and 2 that are repeated. Hopefully, we get to have Binary PSO select those that are informative, and prune those that are redundant or repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(n_samples=500, n_features=20, n_classes=2, \n",
    "                           n_informative=5, n_redundant=0, n_repeated=0, \n",
    "                           random_state=None, shuffle=True)\n",
    "\n",
    "#X, X_test, y, y_test = train_test_split(X, y, test_size=0.20, random_state=None)\n",
    "#X, y = make_classification(n_samples=100, n_features=15, n_classes=3,\n",
    "#                           n_informative=4, n_redundant=1, n_repeated=2,\n",
    "#                           random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X.head()\n",
    "#abc = df.reset_index().values.tolist()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cluster_Path = \"../github/Food_Recommended_Engine_with_PSO/Dataset/Dataset_2020/clustering_result/NF_20201024_HC4/user_clustering_km_pca_pso_c3.csv\"\n",
    "dataset_cluster_df = pd.read_csv(dataset_cluster_Path, sep=',', header=0, na_filter=True)#, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  cluster\n",
       "0        3        2\n",
       "1       15        2\n",
       "2       26        0\n",
       "3       29        0\n",
       "4       56        2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_cluster_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_db_Path = \"../github/Food_Recommended_Engine_with_PSO/Dataset/Dataset_2020/dietary_behavior_rating_explicit.csv\"\n",
    "dataset_db_df = pd.read_csv(dataset_db_Path, sep=',', header=0, na_filter=True)#, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>food_id</th>\n",
       "      <th>food_name</th>\n",
       "      <th>food_score</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pongsakt</td>\n",
       "      <td>1422</td>\n",
       "      <td>เส้นใหญ่แห้งหมูแดง</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pongsakt</td>\n",
       "      <td>1423</td>\n",
       "      <td>เส้นใหญ่ไก่ตุ๋น</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>pongsakt</td>\n",
       "      <td>1468</td>\n",
       "      <td>ข้าวหมูแดง</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>pongsakt</td>\n",
       "      <td>1469</td>\n",
       "      <td>ข้าวหมูแดง+หมูกรอบ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>pongsakt</td>\n",
       "      <td>1471</td>\n",
       "      <td>ข้าวหมูทอด</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id      name  food_id           food_name  food_score  rating\n",
       "0        1  pongsakt     1422  เส้นใหญ่แห้งหมูแดง         1.0       3\n",
       "1        1  pongsakt     1423     เส้นใหญ่ไก่ตุ๋น         0.5       2\n",
       "2        1  pongsakt     1468          ข้าวหมูแดง         1.0       3\n",
       "3        1  pongsakt     1469  ข้าวหมูแดง+หมูกรอบ         1.0       3\n",
       "4        1  pongsakt     1471          ข้าวหมูทอด         1.0       3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_db_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings_matrix = dataset_db_df.pivot_table(values='rating', index='user_id', columns='food_id').fillna(0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings_matrix_cluster = pd.merge(ratings_matrix, dataset_cluster_df, how='inner', on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>1201</th>\n",
       "      <th>1202</th>\n",
       "      <th>1203</th>\n",
       "      <th>1204</th>\n",
       "      <th>1205</th>\n",
       "      <th>1206</th>\n",
       "      <th>1207</th>\n",
       "      <th>1208</th>\n",
       "      <th>1209</th>\n",
       "      <th>...</th>\n",
       "      <th>8084</th>\n",
       "      <th>8085</th>\n",
       "      <th>8086</th>\n",
       "      <th>8087</th>\n",
       "      <th>8088</th>\n",
       "      <th>8089</th>\n",
       "      <th>8090</th>\n",
       "      <th>8091</th>\n",
       "      <th>8092</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  1201  1202  1203  1204  1205  1206  1207  1208  1209  ...  8084  \\\n",
       "0        1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   3.0   \n",
       "1        3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2       15   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3       26   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4       29   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "   8085  8086  8087  8088  8089  8090  8091  8092  cluster  \n",
       "0   0.0   0.0   3.0   0.0   3.0   0.0   0.0   0.0        2  \n",
       "1   0.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0        2  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0        2  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0        0  \n",
       "4   0.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0        0  \n",
       "\n",
       "[5 rows x 394 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_matrix_cluster.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 3, 3, 0], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = ratings_matrix_cluster.iloc[:,-1]\n",
    "y = y.values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ratings_matrix_cluster.drop(labels='cluster', axis=1)\n",
    "X = ratings_matrix_cluster.drop(labels='user_id', axis=1)\n",
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot toy dataset per feature\n",
    "df = pd.DataFrame(X)\n",
    "df['labels'] = pd.Series(y)\n",
    "\n",
    "#sns.pairplot(df, hue='labels');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>384</th>\n",
       "      <th>385</th>\n",
       "      <th>386</th>\n",
       "      <th>387</th>\n",
       "      <th>388</th>\n",
       "      <th>389</th>\n",
       "      <th>390</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5729</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5730</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5731</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5733</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5735</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5736</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5737</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5738</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5739</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5740</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5741</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5742</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5743</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5744</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5745</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5746</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5747</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5748</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5749</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5750</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5751</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5752</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5753</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5754</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5755</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5756</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5757</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5758</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5759 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...  384  385  386  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  3.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "6     3.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0  0.0  0.0  ...  0.0  3.0  2.0   \n",
       "7     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "8     2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  2.0  0.0  ...  0.0  3.0  0.0   \n",
       "9     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "10    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "11    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "12    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "13    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "14    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  3.0   \n",
       "15    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "16    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  3.0   \n",
       "17    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "18    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "19    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "20    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "21    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "22    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  3.0   \n",
       "23    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "24    0.0  0.0  0.0  0.0  0.0  3.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "25    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "26    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "27    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  3.0  0.0   \n",
       "28    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "29    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "5729  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5730  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5731  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5732  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  3.0  0.0  0.0   \n",
       "5733  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5734  0.0  3.0  0.0  0.0  0.0  3.0  0.0  0.0  3.0  0.0  ...  0.0  3.0  0.0   \n",
       "5735  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  3.0  3.0  0.0   \n",
       "5736  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5737  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5738  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  ...  0.0  0.0  0.0   \n",
       "5739  0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5740  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  3.0   \n",
       "5741  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5742  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5743  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5744  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5745  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5746  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  5.0   \n",
       "5747  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5748  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5749  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5750  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5751  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  3.0   \n",
       "5752  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5753  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5754  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  3.0  0.0   \n",
       "5755  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  3.0  0.0  0.0   \n",
       "5756  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5757  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5758  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "      387  388  389  390  391  392  labels  \n",
       "0     0.0  3.0  0.0  0.0  0.0  2.0       2  \n",
       "1     0.0  3.0  0.0  0.0  0.0  2.0       2  \n",
       "2     0.0  0.0  0.0  0.0  0.0  2.0       2  \n",
       "3     0.0  0.0  0.0  0.0  3.0  0.0       0  \n",
       "4     0.0  3.0  0.0  0.0  0.0  0.0       0  \n",
       "5     0.0  4.0  0.0  0.0  0.0  2.0       2  \n",
       "6     3.0  0.0  0.0  0.0  0.0  2.0       2  \n",
       "7     0.0  0.0  0.0  0.0  0.0  2.0       2  \n",
       "8     0.0  0.0  0.0  0.0  0.0  2.0       2  \n",
       "9     0.0  0.0  0.0  0.0  0.0  3.0       3  \n",
       "10    0.0  5.0  0.0  0.0  0.0  0.0       0  \n",
       "11    0.0  3.0  0.0  0.0  0.0  3.0       3  \n",
       "12    0.0  0.0  0.0  0.0  0.0  3.0       3  \n",
       "13    0.0  2.0  0.0  0.0  4.0  2.0       2  \n",
       "14    0.0  3.0  3.0  0.0  0.0  2.0       2  \n",
       "15    0.0  0.0  0.0  0.0  0.0  0.0       0  \n",
       "16    0.0  0.0  0.0  0.0  0.0  0.0       0  \n",
       "17    0.0  0.0  0.0  0.0  0.0  3.0       3  \n",
       "18    0.0  0.0  0.0  0.0  0.0  2.0       2  \n",
       "19    0.0  0.0  0.0  0.0  0.0  2.0       2  \n",
       "20    0.0  0.0  0.0  0.0  0.0  1.0       1  \n",
       "21    0.0  0.0  0.0  0.0  0.0  2.0       2  \n",
       "22    0.0  0.0  0.0  0.0  0.0  3.0       3  \n",
       "23    0.0  3.0  0.0  0.0  0.0  0.0       0  \n",
       "24    0.0  0.0  0.0  0.0  0.0  0.0       0  \n",
       "25    0.0  0.0  0.0  0.0  0.0  2.0       2  \n",
       "26    0.0  0.0  0.0  0.0  0.0  2.0       2  \n",
       "27    0.0  0.0  0.0  0.0  0.0  0.0       0  \n",
       "28    0.0  0.0  0.0  0.0  0.0  3.0       3  \n",
       "29    0.0  3.0  0.0  0.0  0.0  2.0       2  \n",
       "...   ...  ...  ...  ...  ...  ...     ...  \n",
       "5729  0.0  0.0  0.0  0.0  0.0  3.0       3  \n",
       "5730  3.0  0.0  0.0  0.0  0.0  2.0       2  \n",
       "5731  0.0  0.0  0.0  0.0  0.0  0.0       0  \n",
       "5732  0.0  0.0  0.0  0.0  0.0  1.0       1  \n",
       "5733  3.0  3.0  0.0  0.0  0.0  1.0       1  \n",
       "5734  3.0  3.0  0.0  0.0  3.0  1.0       1  \n",
       "5735  0.0  3.0  0.0  0.0  0.0  1.0       1  \n",
       "5736  0.0  3.0  0.0  0.0  3.0  1.0       1  \n",
       "5737  0.0  0.0  0.0  0.0  0.0  1.0       1  \n",
       "5738  0.0  0.0  0.0  0.0  0.0  1.0       1  \n",
       "5739  0.0  3.0  0.0  0.0  0.0  1.0       1  \n",
       "5740  0.0  0.0  0.0  0.0  0.0  1.0       1  \n",
       "5741  0.0  0.0  0.0  0.0  0.0  0.0       0  \n",
       "5742  0.0  0.0  0.0  0.0  0.0  1.0       1  \n",
       "5743  0.0  0.0  0.0  0.0  0.0  1.0       1  \n",
       "5744  0.0  0.0  0.0  0.0  0.0  1.0       1  \n",
       "5745  0.0  0.0  0.0  0.0  0.0  1.0       1  \n",
       "5746  0.0  0.0  0.0  0.0  0.0  3.0       3  \n",
       "5747  0.0  0.0  0.0  0.0  0.0  1.0       1  \n",
       "5748  0.0  0.0  0.0  0.0  0.0  2.0       2  \n",
       "5749  0.0  0.0  0.0  0.0  0.0  2.0       2  \n",
       "5750  0.0  3.0  0.0  0.0  3.0  1.0       1  \n",
       "5751  0.0  0.0  0.0  0.0  3.0  0.0       0  \n",
       "5752  0.0  0.0  0.0  0.0  0.0  0.0       0  \n",
       "5753  0.0  0.0  0.0  0.0  0.0  0.0       0  \n",
       "5754  0.0  0.0  0.0  0.0  0.0  0.0       0  \n",
       "5755  0.0  0.0  0.0  0.0  0.0  0.0       0  \n",
       "5756  0.0  0.0  0.0  0.0  0.0  3.0       3  \n",
       "5757  0.0  0.0  0.0  0.0  0.0  3.0       3  \n",
       "5758  0.0  0.0  0.0  0.0  0.0  0.0       0  \n",
       "\n",
       "[5759 rows x 394 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are some features that causes the two classes to overlap with one another. These might be features that are better off unselected. On the other hand, we can see some feature combinations where the two classes are shown to be clearly separated. These features can hopefully be retained and selected by the binary PSO algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then use a simple logistic regression technique using `sklearn.linear_model.LogisticRegression` to perform classification. A simple test of accuracy will be used to assess the performance of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the custom-objective function\n",
    "As seen above, we can write our objective function by simply taking the performance of the classifier (in this case, the accuracy), and the size of the feature subset divided by the total (that is, divided by 10), to return an error in the data. We'll now write our custom-objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create an instance of the classifier\n",
    "classifier = linear_model.LogisticRegression()\n",
    "#classifier = RandomForestClassifier(n_estimators = 64,\n",
    "#                                    #max_features = 30,\n",
    "#                                    bootstrap = True,\n",
    "#                                    random_state = None)\n",
    "    \n",
    "#clf = forest\n",
    "#clf.fit(X_trainOhFeatures, y_train)\n",
    "#predictions = clf.predict(X_testOhFeatures)\n",
    "#accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "\n",
    "# Define objective function\n",
    "def f_per_particle(m, alpha):\n",
    "    \"\"\"Computes for the objective function per particle\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    m : numpy.ndarray\n",
    "        Binary mask that can be obtained from BinaryPSO, will\n",
    "        be used to mask features.\n",
    "    alpha: float (default is 0.5)\n",
    "        Constant weight for trading-off classifier performance\n",
    "        and number of features\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Computed objective function\n",
    "    \"\"\"\n",
    "    total_features = X.shape[1]\n",
    "    # Get the subset of the features from the binary mask\n",
    "    if np.count_nonzero(m) == 0: \n",
    "        #if the particle subset is only zeros, get the original set of attributes\n",
    "        X_subset = X\n",
    "    else:\n",
    "        X_subset = X[:,m==1]\n",
    "        \n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X_subset, y, test_size=0.20, random_state=None)\n",
    "    # Perform classification and store performance in P\n",
    "    #classifier.fit(X_train, y_train)\n",
    "    #P = (classifier.predict(X_test) == y_test).mean()\n",
    "    \n",
    "    scores = cross_val_score(classifier, X_subset, y, cv=3)\n",
    "    #print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    P = scores.mean()\n",
    "    particleScore.append(P)\n",
    "    particleSize.append(X_subset.shape[1])\n",
    "    # Compute for the objective function\n",
    "    j = (alpha * (1.0 - P)\n",
    "        + (1.0 - alpha) * (1 - (X_subset.shape[1] / total_features)))\n",
    "    \n",
    "    #j = (alpha * (1.0 - P)) + (1 - alpha) * (1 - (total_features - X_subset.shape[1]) / total_features)\n",
    "    #print(\"Particle j: \", j)\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, alpha=0.9):\n",
    "    \"\"\"Higher-level method to do classification in the\n",
    "    whole swarm.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
    "        The swarm that will perform the search\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of shape (n_particles, )\n",
    "        The computed loss for each particle\n",
    "    \"\"\"\n",
    "    n_particles = x.shape[0]\n",
    "    j = [f_per_particle(x[i], alpha) for i in range(n_particles)]\n",
    "    #print(\"f j: \", j)\n",
    "    return np.array(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Binary PSO\n",
    "With everything set-up, we can now use Binary PSO to perform feature selection. For now, we'll be doing a global-best solution by setting the number of neighbors equal to the number of particles. The hyperparameters are also set arbitrarily. Moreso, we'll also be setting the distance metric as 2 (truth is, it's not really relevant because each particle will see one another)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyswarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyswarms.utils.environments'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-1982b63e2753>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyswarms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvironments\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPlotEnvironment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyswarms.utils.environments'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "import time\n",
    "from pyswarms.utils.environments import PlotEnvironment\n",
    "\n",
    "start = dt.now()\n",
    "print(\"Started at: \", str(start))\n",
    "particleScore = list()\n",
    "particleSize = list()\n",
    "#mySubsets = list()\n",
    "\n",
    "# Initialize swarm, arbitrary\n",
    "options = {'c1': 2, 'c2': 2, 'w':0.3, 'k': 20, 'p':2}\n",
    "\n",
    "# Call instance of PSO\n",
    "dimensions = X.shape[1] # dimensions should be the number of features\n",
    "#optimizer.reset()\n",
    "#optimizer = ps.single.GlobalBestPSO(n_particles=1, dimensions=dimensions,\n",
    "#                                    options=options)\n",
    "optimizer = ps.discrete.BinaryPSO(n_particles=20, dimensions=dimensions, options=options)\n",
    "\n",
    "# Perform optimization\n",
    "#cost, pos = optimizer.optimize(f, print_step=1, iters=10, verbose=2)\n",
    "\n",
    "\n",
    "# Initialize plot environment\n",
    "plt_env = PlotEnvironment(optimizer, f, 10)\n",
    "\n",
    "# Plot the cost\n",
    "plt_env.plot_cost(figsize=(8,6));\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#print(cost,pos)\n",
    "end = dt.now()\n",
    "print(\"Finished at: \", str(end))\n",
    "total = end-start\n",
    "print(\"Total time spent: \", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://pyswarms.readthedocs.io/en/latest/examples/visualization.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31448533 0.31654327 0.31416821 0.31215416 0.31230486 0.30595629\n",
      " 0.30642416 0.30580338 0.30301888 0.30493664]\n",
      "[0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 0\n",
      " 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1\n",
      " 1 0 0 1 0 0 1 1 1 0 0 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0\n",
      " 0 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 0 0\n",
      " 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1\n",
      " 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(optimizer.get_mean_pbest_history)\n",
    "print(optimizer.personal_best_pos[5])\n",
    "\n",
    "#mean_pbest_history\n",
    "\n",
    "#optimizer.get_pos_history\n",
    "#optimizer.get_velocity_history\n",
    "#optimizer.pos_history #subsets of attributes [iters[particles]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnEAAAGtCAYAAAB5mSLxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27ae75e6eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "iterations = list(range(1,len(optimizer.get_cost_history)+1))\n",
    "plt.figure(figsize=(10,7))\n",
    "#plt.xlabel('2^i classes')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error Rate')\n",
    "#get_cost_history #erro médio da iteracao\n",
    "#optimizer.mean_pbest_history #erro minimo pbest\n",
    "plt.plot(iterations, optimizer.mean_pbest_history, 'r', label='pBest') \n",
    "plt.plot(iterations, optimizer.get_cost_history, 'b', label='cost') \n",
    "plt.legend()\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "#plt.savefig(\"D:/USP/2018-1/Computação Bioinspirada/Trabalhos/iterationVSerrorRate2.png\", format=\"PNG\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAAGtCAYAAACrySipAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27ae79583c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt #MatPlotLib usado para desenhar o gráfico criado com o NetworkX\n",
    "\n",
    "#iterations = list(range(1,len(optimizer.get_cost_history)+1))\n",
    "plt.figure(figsize=(10,7))\n",
    "#plt.xlabel('2^i classes')\n",
    "plt.xlabel('subsetSize')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(particleSize, particleScore, 'bo')\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "#plt.savefig(\"D:/USP/2018-1/Computação Bioinspirada/Trabalhos/iterationVSerrorRate2.png\", format=\"PNG\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then train the classifier using the positions found by running another instance of logistic regression. We can compare the performance when we're using the full set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full set Accuracy: 0.74 (+/- 0.07)\n",
      "----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74 (+/- 0.08) [0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0\n",
      " 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 1 0\n",
      " 1 1 0 0 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 1 1 0 1 0 1\n",
      " 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0\n",
      " 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1\n",
      " 1 1 0 1 0 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1\n",
      " 0 1 1 1 1 0 0 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 1\n",
      " 0 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74 (+/- 0.09) [1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 0\n",
      " 1 0 0 0 0 0 1 0 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1\n",
      " 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 1 1 1 0\n",
      " 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 1 1 1 0\n",
      " 0 1 0 1 1 1 0 1 0 1 1 1 0 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1\n",
      " 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0\n",
      " 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0\n",
      " 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 1 0 1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74 (+/- 0.12) [1 0 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 0\n",
      " 1 1 1 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1\n",
      " 0 1 0 0 1 0 1 0 1 0 1 0 0 1 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1\n",
      " 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 0\n",
      " 1 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0\n",
      " 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1\n",
      " 1 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 0\n",
      " 1 0 0 1 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75 (+/- 0.11) [0 1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1\n",
      " 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 0 1 1\n",
      " 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1 0\n",
      " 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1\n",
      " 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 0\n",
      " 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 0\n",
      " 0 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73 (+/- 0.12) [1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0\n",
      " 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0\n",
      " 0 0 1 1 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 1\n",
      " 0 1 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1\n",
      " 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 1 0\n",
      " 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0\n",
      " 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 1 1 1 0 0\n",
      " 1 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75 (+/- 0.09) [0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 0\n",
      " 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1\n",
      " 1 0 0 1 0 0 1 1 1 0 0 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0\n",
      " 0 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 0 0\n",
      " 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1\n",
      " 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72 (+/- 0.09) [0 0 1 0 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0\n",
      " 0 0 1 1 1 1 1 1 0 0 0 1 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 1 1 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1\n",
      " 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 1 1\n",
      " 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 0 1\n",
      " 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 1 0 0 0 1 1 1 1\n",
      " 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1\n",
      " 0 0 1 1 1 0 0 1 0 1 1 0 1 0 1 1 1 0 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.70 (+/- 0.07) [1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 0 0 1 1 0 1\n",
      " 0 0 1 0 1 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0\n",
      " 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 0\n",
      " 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 0 0 0 1 1 0 1\n",
      " 1 1 1 1 1 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1\n",
      " 1 0 1 0 1 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 1 0 0\n",
      " 0 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72 (+/- 0.10) [1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 0 1 1 1\n",
      " 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0\n",
      " 0 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 1 0 1\n",
      " 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 0 0 1 0 1 0\n",
      " 0 1 1 1 1 1 1 0 0 1 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1 0 1\n",
      " 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.71 (+/- 0.08) [0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1\n",
      " 0 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0\n",
      " 0 1 1 0 1 1 0 0 1 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 1\n",
      " 0 0 1 1 1 0 1 1 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 1 0\n",
      " 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 1 1 0 1\n",
      " 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 1 1 1 1 0 1\n",
      " 0 1 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72 (+/- 0.09) [0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 0\n",
      " 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1\n",
      " 1 1 1 0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 1 1 1\n",
      " 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1\n",
      " 0 1 0 1 1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0\n",
      " 0 1 1 0 0 0 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 0\n",
      " 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 1 0 1 0 0 1 1 0 0 1 0\n",
      " 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74 (+/- 0.09) [0 0 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 1 1 1 0 0 1 0\n",
      " 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 0 1 0 0 1 1 0 1 1 0 1 0 0 0 1 1\n",
      " 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1\n",
      " 0 0 0 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0\n",
      " 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1 1 0\n",
      " 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0\n",
      " 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0 1 0\n",
      " 0 0 0 1 1 0 0 0 1 1 1 1 1 0 0 1 1 0 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73 (+/- 0.08) [1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0 0 0 0 0\n",
      " 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1\n",
      " 1 1 1 1 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1\n",
      " 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1\n",
      " 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 0 1 0 0 0 1 1 1 0 1 0 1 0 0\n",
      " 0 1 0 0 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1 0 1 0 0 1 1\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72 (+/- 0.09) [0 1 1 0 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 0 1 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0\n",
      " 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 1 1\n",
      " 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 1 1 1 0 0 1 1 1 0 1\n",
      " 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 0\n",
      " 1 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 1 0 1\n",
      " 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1\n",
      " 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 1 0 1 0\n",
      " 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73 (+/- 0.07) [1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 0 0 1 1 0\n",
      " 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 0\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 0 0 0 0\n",
      " 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1\n",
      " 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1\n",
      " 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 0 1\n",
      " 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74 (+/- 0.10) [1 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1\n",
      " 1 0 1 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1\n",
      " 0 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1\n",
      " 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 0 1\n",
      " 0 1 1 0 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1\n",
      " 0 1 0 1 0 1 0 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 1\n",
      " 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0\n",
      " 1 1 0 0 1 0 0 1 0 1 0 0 1 1 0 0 1 1 1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72 (+/- 0.07) [1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1\n",
      " 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1\n",
      " 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0\n",
      " 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0\n",
      " 1 0 1 0 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 1\n",
      " 1 0 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 0 1 1\n",
      " 1 0 1 1 0 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 1 1 0 1\n",
      " 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72 (+/- 0.09) [1 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 1\n",
      " 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1 0 0 1\n",
      " 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
      " 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0\n",
      " 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 1\n",
      " 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0\n",
      " 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0\n",
      " 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72 (+/- 0.10) [0 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0\n",
      " 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0\n",
      " 1 0 0 1 0 1 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0\n",
      " 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1\n",
      " 0 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 1 0 1 1 0 0 1 1 0 0\n",
      " 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 1 1 0 1 1 0 1 0 1 0 1 1 1 0 0 0 1 1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73 (+/- 0.10) [1 0 0 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1\n",
      " 0 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0 1 1\n",
      " 0 1 0 1 1 0 0 1 0 1 0 1 0 0 1 1 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 1 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1\n",
      " 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 0 0 0 0 1 1\n",
      " 1 0 0 0 0 0 1 0 1 1 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 0 0 1\n",
      " 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0\n",
      " 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# Create two instances of LogisticRegression\n",
    "#classfier = linear_model.LogisticRegression()\n",
    "classifier = RandomForestClassifier(n_estimators = 64,\n",
    "                                    #max_features = 30,\n",
    "                                    bootstrap = True,\n",
    "                                    random_state = None)\n",
    "\n",
    "rank = list()\n",
    "\n",
    "fullSet = cross_val_score(classifier, X, y, cv=5)\n",
    "print(\"Full set Accuracy: %0.2f (+/- %0.2f)\" % (fullSet.mean(), fullSet.std() * 2))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "bests = optimizer.personal_best_pos #optimizer.get_pos_history\n",
    "for b in bests:\n",
    "    # Get the selected features from the final positions\n",
    "    X_selected_features = X[:,b==1]  # subset\n",
    "\n",
    "    # Perform classification and store performance in P\n",
    "    #classifier.fit(X_selected_features, y)\n",
    "    scores = cross_val_score(classifier, X_selected_features, y, cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2), b)\n",
    "    rank.append([scores.mean(), b])\n",
    "    # Compute performance\n",
    "    #subset_performance = (c1.predict(X_selected_features) == y).mean()\n",
    "    #subset_performance = (classifier.predict(X_selected_features) == y).mean()\n",
    "    \n",
    "\n",
    "    #print('Subset performance: %.3f' % (subset_performance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full set accuracy: 0.7418\n",
      "Best subset accuracy: 0.751\n",
      "Best subset length: 132\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "             length  |  accuracy\n",
      "full set      279        0.7418\n",
      "best subset   132        0.751\n"
     ]
    }
   ],
   "source": [
    "fullSetAccuracy = round(fullSet.mean(),4)\n",
    "bestSubsetAccuracy = round(max(rank)[0],4)\n",
    "bestSubsetLength = sum(max(rank)[1])\n",
    "\n",
    "print(\"Full set accuracy:\", fullSetAccuracy)\n",
    "print(\"Best subset accuracy:\", bestSubsetAccuracy)\n",
    "print(\"Best subset length:\", bestSubsetLength)\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"             length  |  accuracy\")\n",
    "print(\"full set     \", X.shape[1], \"      \", fullSetAccuracy)\n",
    "print(\"best subset  \", bestSubsetLength, \"      \", bestSubsetAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ignore below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two instances of LogisticRegression\n",
    "#classfier = linear_model.LogisticRegression()\n",
    "classifier = RandomForestClassifier(n_estimators = 64,\n",
    "                                    #max_features = 30,\n",
    "                                    bootstrap = True,\n",
    "                                    random_state = None)\n",
    "\n",
    "scores = cross_val_score(classifier, X, y, cv=10)\n",
    "print(\"Accuracy full set: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2), \"len:\",X.shape[1])\n",
    "\n",
    "# Get the selected features from the final positions\n",
    "X_selected_featuresPSO = X[:,pos==1]  # subset\n",
    "X_selected_featuresReal = X[:,0:5] #real subset\n",
    "\n",
    "# Perform classification and store performance in P\n",
    "#classifier.fit(X_selected_features, y)\n",
    "scoresReal = cross_val_score(classifier, X_selected_featuresReal, y, cv=10)\n",
    "scoresPSO = cross_val_score(classifier, X_selected_featuresPSO, y, cv=10)\n",
    "\n",
    "# Compute performance\n",
    "#subset_performance = (c1.predict(X_selected_features) == y).mean()\n",
    "#subset_performance = (classifier.predict(X_selected_features) == y).mean()\n",
    "\n",
    "#print('Subset performance: %.3f' % (subset_performance))\n",
    "print(\"Accuracy Real subset: %0.2f (+/- %0.2f)\" % (scoresReal.mean(), scoresReal.std() * 2), \"len:\", X_selected_featuresReal.shape[1])\n",
    "print(\"Accuracy PSO subset: %0.2f (+/- %0.2f)\" % (scoresPSO.mean(), scoresPSO.std() * 2), \"len:\", X_selected_featuresPSO.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# Create two instances of LogisticRegression\n",
    "#classfier = linear_model.LogisticRegression()\n",
    "classifier = RandomForestClassifier(n_estimators = 64,\n",
    "                                    #max_features = 30,\n",
    "                                    bootstrap = True,\n",
    "                                    random_state = None)\n",
    "\n",
    "scores = cross_val_score(classifier, X, y, cv=5)\n",
    "print(\"Full set Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "bests = optimizer.personal_best_pos #optimizer.personal_best_pos\n",
    "for best in bests:\n",
    "    for b in best:\n",
    "        # Get the selected features from the final positions\n",
    "        X_selected_features = X[:,b==1]  # subset\n",
    "\n",
    "        # Perform classification and store performance in P\n",
    "        #classifier.fit(X_selected_features, y)\n",
    "        scores = cross_val_score(classifier, X_selected_features, y, cv=5)\n",
    "\n",
    "        # Compute performance\n",
    "        #subset_performance = (c1.predict(X_selected_features) == y).mean()\n",
    "        #subset_performance = (classifier.predict(X_selected_features) == y).mean()\n",
    "        print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2), b)\n",
    "\n",
    "    #print('Subset performance: %.3f' % (subset_performance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important advantage that we have is that we were able to reduce the features (or do dimensionality reduction) on our data. This can save us from the [curse of dimensionality](http://www.stat.ucla.edu/~sabatti/statarray/textr/node5.html), and may in fact speed up our classification.\n",
    "\n",
    "Let's plot the feature subset that we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot toy dataset per feature\n",
    "df1 = pd.DataFrame(X_selected_features)\n",
    "df1['labels'] = pd.Series(y)\n",
    "\n",
    "sns.pairplot(df1, hue='labels')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
